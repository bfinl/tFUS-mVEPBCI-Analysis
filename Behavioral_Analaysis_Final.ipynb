{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894df618",
   "metadata": {},
   "source": [
    "# mVEP Behavioral Analysis\n",
    "\n",
    "This notebook contains the analysis codes for mVEP BCI behavioral data.\n",
    "\n",
    "Scripts are primarily written by Joshua Kosnoff. I've tried to give proper credit to 3rd party sites where due. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b06446",
   "metadata": {},
   "source": [
    "## Load in the behavioral data outputs\n",
    "\n",
    "The BCI behavioral data are saved in the BCI Outcomes csv file. We can load in the file with the Pandas package. Note that this csv file is publically available on FigShare along with the rest of the data from this study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce72b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Scans</th>\n",
       "      <th>Sonications</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subj01</td>\n",
       "      <td>Non-Modulated</td>\n",
       "      <td>6HYNBI6DSB5MONZ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subj01</td>\n",
       "      <td>tFUS-GC</td>\n",
       "      <td>CARNEAOE_MELLIN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subj02</td>\n",
       "      <td>tFUS-GC</td>\n",
       "      <td>CALNBGKERME_LQO</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subj02</td>\n",
       "      <td>Decoupled-Sham</td>\n",
       "      <td>SARNEMI26YELLON</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subj02</td>\n",
       "      <td>Non-Modulated</td>\n",
       "      <td>C4QN8GCE5PBKLNR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subj       Condition       Prediction  Scans  Sonications  Order\n",
       "0  Subj01   Non-Modulated  6HYNBI6DSB5MONZ      2            0      1\n",
       "1  Subj01         tFUS-GC  CARNEAOE_MELLIN      2            2      2\n",
       "2  Subj02         tFUS-GC  CALNBGKERME_LQO      3            4      1\n",
       "3  Subj02  Decoupled-Sham  SARNEMI26YELLON      3            4      2\n",
       "4  Subj02   Non-Modulated  C4QN8GCE5PBKLNR      3            0      3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "my_df = pd.read_csv(\"/Users/jkosnoff/Desktop/BCI Outcomes.csv\")\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0ec940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total N:  25\n",
      "tFUS-GC N:  25\n",
      "tFUS-CP N:  16\n",
      "Non-Modulated N:  25\n",
      "Decoupled-Sham N:  19\n"
     ]
    }
   ],
   "source": [
    "# Get study statistics\n",
    "\n",
    "print(\"Total N: \", len(np.unique(my_df.Subj)))\n",
    "print(\"tFUS-GC N: \", len(np.unique(my_df[\"Subj\"].loc[my_df.Condition == \"tFUS-GC\"])))\n",
    "print(\"tFUS-CP N: \", len(np.unique(my_df[\"Subj\"].loc[my_df.Condition == \"tFUS-GP\"])))\n",
    "print(\"Non-Modulated N: \", len(np.unique(my_df[\"Subj\"].loc[my_df.Condition == \"Non-Modulated\"])))\n",
    "print(\"Decoupled-Sham N: \", len(np.unique(my_df[\"Subj\"].loc[my_df.Condition == \"Decoupled-Sham\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a32ab",
   "metadata": {},
   "source": [
    "## Calculate euclidean error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e2e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "\n",
    "# Load the mVEP Configs json\n",
    "with open(fr\"/Users/jkosnoff/Library/CloudStorage/Box-Box/mVEP_BCI_cfgs.json\") as f:\n",
    "    mVEP_cfgs = json.load(f)\n",
    "\n",
    "def calc_euclidean_error(arr1, arr2, grid = np.array(mVEP_cfgs[\"keyboard\"])):\n",
    "    \"\"\"\n",
    "    The Euclidean error is the Euclidean distance on the virtual keyboard between the intended letter\n",
    "    and the BCI's predicted letter, normalized to a percentage with the maximum keyboard's distance (6*sqrt(2)) \n",
    "    and averaged for the number of letters considered\n",
    "    \n",
    "    Inputs:\n",
    "        arr1: the array of the first letter set\n",
    "        arr2: the array of the second letter set\n",
    "        grid: the 2D array corresponding to the virtual keyboard\n",
    "        \n",
    "    Note that this calculation goes array index-by-index, so the inputs should be of equal length.\n",
    "    \n",
    "    Returns:\n",
    "        err: the Euclidean error\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(arr1) != len(arr2):\n",
    "        print(f\"Warning! Inputs are of unequal length {arr1} {arr2}. Truncating . . .\")\n",
    "        arr1 = arr1[:min(len(arr1), len(arr2))]\n",
    "        arr2 = arr2[:min(len(arr1), len(arr2))]\n",
    "    \n",
    "    # Initialize error to 0\n",
    "    err = 0\n",
    "    for i, j in zip(arr1, arr2):\n",
    "        if i != j:\n",
    "\n",
    "            err += np.sqrt((int(np.where(grid == i)[0]) - int(np.where(grid == j)[0]))**(2) +\n",
    "                           (int(np.where(grid == i)[1]) - int(np.where(grid == j)[1]))**(2))\n",
    "    \n",
    "    # Normalize error w.r.t. keyboard\n",
    "    err /= (grid.shape[0] **(2) + grid.shape[1]**(2))**(0.5) \n",
    "    \n",
    "    # Normalize error w.r.t string length\n",
    "    err /= len(arr1) \n",
    "    \n",
    "    # Multiply by 100 to convert to a percentage\n",
    "    err *= 100\n",
    "    \n",
    "    return err\n",
    "\n",
    "\n",
    "def return_target(subject_id, prediction):\n",
    "    \"\"\"\n",
    "    Some subjects had slightly different target strings then others. This returns the proper target string\n",
    "    for each subject\n",
    "    \"\"\"\n",
    "\n",
    "    if subject_id in [\"Subj07\",\"Subj04\"]:\n",
    "        target = \"CARNEGIE4MELLON\"\n",
    "    elif len(prediction) == 14:\n",
    "        target = \"CARNEGIEMELLON\"\n",
    "    else:\n",
    "        target = \"CARNEGIE_MELLON\"\n",
    "        \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5539bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target\n",
    "\n",
    "my_df[\"target\"] = my_df.apply(lambda x: return_target(x['Subj'], x['Prediction']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595141ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "expanded_df = pd.DataFrame(columns = [\"Subj\", \"Condition\", \"Prediction\", \"Scans\", \"Sonications\", \"target\", \"Order\"])\n",
    "for i in range(len(my_df)):\n",
    "    targ = my_df[\"target\"].iloc[i]\n",
    "    for l in range(len(targ)):\n",
    "        expanded_df.loc[len(expanded_df)] = {\"Subj\": my_df[\"Subj\"].iloc[i], \n",
    "                                            \"Condition\": my_df[\"Condition\"].iloc[i],\n",
    "                                            \"Prediction\":my_df[\"Prediction\"].iloc[i][l],\n",
    "                                            \"target\": my_df[\"target\"].iloc[i][l], \n",
    "                                            \"Sonications\": my_df[\"Sonications\"].iloc[i], \n",
    "                                            \"Scans\": my_df[\"Scans\"].iloc[i],\n",
    "                                            \"Order\": my_df[\"Order\"].iloc[i]\n",
    "                                            }\n",
    "\n",
    "        \n",
    "encoder_dict = {key: value for value, key in enumerate(np.unique(expanded_df.Subj))}\n",
    "\n",
    "expanded_df[\"EE\"] = expanded_df.apply(lambda x: calc_euclidean_error(x['Prediction'], x['target']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa88f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Outlier_Tests import IQR_Outlier_test\n",
    "\n",
    "subj_avg_clean_df = pd.DataFrame(columns = [\"Subj\", \"Condition\", \"EE\", \"Scans\", \"Order\", \"Sonications\"])\n",
    "\n",
    "for subject in np.unique(expanded_df.Subj):\n",
    "    for condition in np.unique(expanded_df[\"Condition\"].loc[expanded_df.Subj == subject]):\n",
    "        scans = expanded_df[\"Scans\"].loc[(expanded_df.Condition == condition) & (expanded_df.Subj == subject)].values[0]\n",
    "        order = expanded_df[\"Order\"].loc[(expanded_df.Condition == condition) & (expanded_df.Subj == subject)].values[0]\n",
    "        sonications = expanded_df[\"Sonications\"].loc[(expanded_df.Condition == condition) & (expanded_df.Subj == subject)].values[0]\n",
    "        \n",
    "        \n",
    "        ee = expanded_df[\"EE\"].loc[(expanded_df.Condition == condition) & (expanded_df.Subj == subject)].values\n",
    "        len1 = len(ee)\n",
    "                \n",
    "        # Remove Outliers\n",
    "        ee = ee[~np.array(IQR_Outlier_test(ee))]\n",
    "        \n",
    "        len2 = len(ee) \n",
    "        # print(f\"{subject, condition} Removed {len1 - len2} outliers\")\n",
    "        \n",
    "        for i in range(len2):\n",
    "            subj_avg_clean_df.loc[len(subj_avg_clean_df)] = {\"Subj\": subject, \"Condition\": condition, \n",
    "                                                             \"EE\": ee[i], \n",
    "                                                             \"Scans\": scans,\n",
    "                                                             \"Order\": order,\n",
    "                                                             \"Sonications\": sonications}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5294c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the euclidean errors to a csv to use in R\n",
    "# Note that these values are present under Source Data Figure 1\n",
    "\n",
    "subj_avg_clean_df.to_csv(r\"/Users/jkosnoff/Downloads/Removed_Outliers_IQR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1d720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "Outlier_Tests       NA\n",
       "matplotlib          3.7.0\n",
       "numpy               1.23.5\n",
       "pandas              1.5.3\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                         9.4.0\n",
       "PyObjCTools                 NA\n",
       "appnope                     0.1.2\n",
       "asttokens                   NA\n",
       "backcall                    0.2.0\n",
       "bottleneck                  1.3.5\n",
       "cffi                        1.15.1\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.2\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.5.1\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.4\n",
       "executing                   0.8.3\n",
       "ipykernel                   6.19.2\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.1\n",
       "jupyter_server              1.23.4\n",
       "kiwisolver                  1.4.4\n",
       "metapensiero                NA\n",
       "mpl_toolkits                NA\n",
       "numexpr                     2.8.4\n",
       "packaging                   22.0\n",
       "parso                       0.8.3\n",
       "pexpect                     4.8.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                3.7.0\n",
       "prompt_toolkit              3.0.36\n",
       "psutil                      5.9.0\n",
       "ptyprocess                  0.7.0\n",
       "pure_eval                   0.2.2\n",
       "pyarrow                     11.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.6.0\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.15.1\n",
       "pyparsing                   3.0.9\n",
       "pytz                        2022.7\n",
       "ruamel                      NA\n",
       "setuptools                  68.2.2\n",
       "six                         1.16.0\n",
       "sphinxcontrib               NA\n",
       "stack_data                  0.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.7.1\n",
       "typing_extensions           NA\n",
       "wcwidth                     0.2.5\n",
       "zmq                         23.2.0\n",
       "zope                        NA\n",
       "zstandard                   0.19.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.10.0\n",
       "jupyter_client      7.3.4\n",
       "jupyter_core        5.2.0\n",
       "jupyterlab          3.5.3\n",
       "notebook            6.5.2\n",
       "-----\n",
       "Python 3.10.9 (main, Mar  1 2023, 12:20:14) [Clang 14.0.6 ]\n",
       "macOS-13.4.1-arm64-arm-64bit\n",
       "-----\n",
       "Session information updated at 2024-04-10 16:18\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the versions of the used software for this analysis\n",
    "\n",
    "import session_info\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
